# ==========================================================
# ê´‘ì£¼ê´‘ì—­ì‹œ ê±´ì¶• ê´€ê´‘ìì›
# ìœ„ì¹˜ ì •ë³´ íŒŒì•… + êµ¬ë³„ í‚¤ì›Œë“œ ë¶„ì„ ì‹œìŠ¤í…œ
# ==========================================================
# ì£¼ìš” ê¸°ëŠ¥
# 1. CSV ë°ì´í„° ë¡œë“œ
# 2. ì£¼ì†Œ â†’ ìœ„ë„/ê²½ë„ ë³€í™˜ (ì§€ì˜¤ì½”ë”©)
# 3. ì£¼ì†Œì—ì„œ 'êµ¬(å€)' ì •ë³´ ì¶”ì¶œ
# 4. êµ¬ë³„ ì„¤ëª… í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
# 5. ì§€ë„ ì‹œê°í™” (ìœ„ì¹˜ ì •ë³´ ì¤‘ì‹¬)
# ==========================================================

# ----------------------------------------------------------
# ìƒìˆ˜ ë° ì „ì²˜ë¦¬ ì„¤ì •
# ----------------------------------------------------------

import re
from pathlib import Path
from collections import Counter
import math
import pandas as pd
from kiwipiepy import Kiwi
from keybert import KeyBERT
import folium

from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
from tqdm import tqdm

DISTRICTS = ["ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬", "ê´‘ì‚°êµ¬"]

# ë” ê°•í•œ íŒ¨í„´ ì œê±°
RE_ORD = re.compile(r"ì œ\s*\d+\s*(?:í˜¸|íšŒ)")
RE_YEAR = re.compile(r"\d{3,4}\s*ë…„")
RE_NUM = re.compile(r"\b\d+(?:[.,]\d+)?\b")
RE_PUNCT = re.compile(r"[^\w\sÂ·]")
RE_MULTI = re.compile(r"\s+")

STOPWORDS = set([
    "ê´‘ì£¼", "ê´‘ì£¼ê´‘ì—­ì‹œ", "ëŒ€í•œë¯¼êµ­", "êµ­ê°€", "ë“±ë¡", "ë“±ë¡ë¬¸í™”ì¬", "êµ­ê°€ë“±ë¡ë¬¸í™”ì¬",
    "ìœ í˜•ë¬¸í™”ì¬", "ë¬¸í™”ì¬ìë£Œ", "ê¸°ë…ë¬¼", "ëª…ìŠ¹", "ì‚¬ì ", "ì§€ì •", "ìŠ¹ê²©",
    "ì¡°ì„ ì‹œëŒ€", "ì¼ì œê°•ì ê¸°", "ê·¼ëŒ€", "í˜„ëŒ€", "ê°œê´€", "ì¤€ê³µ", "ì™„ê³µ", "ì¦ì¶•", "ì¤‘ê±´",
    "ë³µì›", "ë³´ìˆ˜", "ì´ì „", "ì‹ ì¶•", "ë¦¬ëª¨ë¸ë§",
    "ê±´ë¬¼", "ê±´ì¶•", "ê±´ì¶•ë¬¼", "ì‹œì„¤", "ê³µê°„", "ì¥ì†Œ", "ì§€ì—­", "í˜„ì¬", "ë‹¹ì‹œ",
    "ê·œëª¨", "êµ¬ì„±", "ê°€ì¹˜", "íŠ¹ì§•", "í™œìš©", "ì‚¬ìš©", "ë¶€ë¬¸"
])

# âœ… Kiwië¡œ "ëª…ì‚¬"ë§Œ ì¶”ì¶œí•´ì„œ í‚¤ì›Œë“œ í›„ë³´ë¥¼ ê¹”ë”í•˜ê²Œ ë§Œë“¤ê¸°
kiwi = Kiwi()

# ----------------------------------------------------------
# 1. ë°ì´í„° ë¡œë“œ
# ----------------------------------------------------------

INPUT_CSV = "./GT_ARCHITECTURE_TOURISM_RESOURCES_2025.csv"
OUTPUT_CSV = "./GT_ARCHITECTURE_TOURISM_RESOURCES_2025_GEO.csv"
OUTPUT_MAP = "./gwangju_architecture_map.html"

# ----------------------------------------------------------
# í•µì‹¬ í•¨ìˆ˜: í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¶„ì„
# ----------------------------------------------------------

def extract_district(addr: str):
    """
    ì£¼ì†Œ ë¬¸ìì—´ì—ì„œ ê´‘ì£¼ê´‘ì—­ì‹œì˜ 'êµ¬' ì •ë³´ ì¶”ì¶œ
    """
    if not isinstance(addr, str):
        return None
    for d in DISTRICTS:
        if d in addr:
            return d
    return None

def clean_text(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬: ìˆ«ì, ê¸°í˜¸, ì •ë ¬ ì œê±°
    """
    if not isinstance(text, str):
        return ""
    t = text.replace("5Â·18", "ì˜¤ì›”ë¯¼ì£¼í™”")   # ì˜ë¯¸ ìˆëŠ” ì˜ˆì™¸ëŠ” ì‚´ë¦¬ê¸°
    t = RE_ORD.sub(" ", t)
    t = RE_YEAR.sub(" ", t)
    t = RE_NUM.sub(" ", t)
    t = RE_PUNCT.sub(" ", t)
    t = RE_MULTI.sub(" ", t).strip()
    return t

def nouns_only(text: str):
    """
    Kiwië¡œ ëª…ì‚¬ë§Œ ì¶”ì¶œ
    """
    if not text:
        return []
    tokens = []
    for token, pos, _, _ in kiwi.analyze(text)[0][0]:
        # NNG: ì¼ë°˜ëª…ì‚¬, NNP: ê³ ìœ ëª…ì‚¬
        if pos in ("NNG", "NNP"):
            if len(token) >= 2 and token not in STOPWORDS:
                tokens.append(token)
    return tokens

def log_odds_dirichlet(one: Counter, rest: Counter, alpha=0.01, topn=30, min_count=2):
    """
    One-vs-Rest ë¡œê·¸ ì˜¤ì¦ˆ ë¹„ìœ¨ ê³„ì‚°
    """
    vocab = set(one.keys()) | set(rest.keys())
    n1, n0 = sum(one.values()), sum(rest.values())

    out = []
    V = len(vocab) if len(vocab) else 1
    for w in vocab:
        c1, c0 = one.get(w, 0), rest.get(w, 0)
        if c1 < min_count:
            continue
        p1 = (c1 + alpha) / (n1 + alpha * V)
        p0 = (c0 + alpha) / (n0 + alpha * V)
        score = math.log(p1 / (1 - p1 + 1e-12)) - math.log(p0 / (1 - p0 + 1e-12))
        out.append((w, score, c1, c0))
    out.sort(key=lambda x: x[1], reverse=True)
    return out[:topn]

def run_pipeline(csv_path: str, out_prefix="gwangju_ai", topn=30):
    """
    One-vs-Rest íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    csv_path = Path(csv_path)
    df = pd.read_csv(csv_path, encoding="utf-8")

    df["DIST"] = df["ADDR"].apply(extract_district)
    df = df[df["DIST"].isin(DISTRICTS)].copy()
    df["DC_CN"] = df["DC_CN"].fillna("").map(clean_text)

    print("[êµ¬ë³„ ë ˆì½”ë“œ ìˆ˜]")
    print(df["DIST"].value_counts().reindex(DISTRICTS).fillna(0).astype(int).to_string())

    # êµ¬ë³„ í† í° ì¹´ìš´íŠ¸(ëª…ì‚¬ë§Œ)
    counters = {}
    for dist in DISTRICTS:
        sub = df[df["DIST"] == dist]
        toks = []
        for s in sub["DC_CN"].tolist():
            toks.extend(nouns_only(s))
        counters[dist] = Counter(toks)

    # One-vs-Rest "ì°¨ì´" í‚¤ì›Œë“œ
    rows = []
    for dist in DISTRICTS:
        one = counters[dist]
        rest = Counter()
        for other in DISTRICTS:
            if other != dist:
                rest += counters[other]

        ranked = log_odds_dirichlet(one, rest, alpha=0.01, topn=topn, min_count=2)
        for r, (kw, score, c1, c0) in enumerate(ranked, 1):
            rows.append({
                "DIST": dist, "RANK": r, "KEYWORD": kw,
                "SCORE_LOG_ODDS": score,
                "COUNT_IN_DIST": c1, "COUNT_IN_OTHERS": c0
            })

    out = pd.DataFrame(rows).sort_values(["DIST", "RANK"])
    out_path = csv_path.parent / f"{out_prefix}_onevsrest_nouns.csv"
    out.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"\nì €ì¥: {out_path}")

    # ì½˜ì†” ìš”ì•½
    for dist in DISTRICTS:
        top10 = out[out["DIST"] == dist].head(10)["KEYWORD"].tolist()
        print(f"- {dist}: " + (", ".join(top10) if top10 else "(ê²°ê³¼ ì—†ìŒ)"))

    return out

def run_keybert_by_district(csv_path: str, out_prefix="ai_keywords", topn=30):
    """
    ëª…ì‚¬ ë¹ˆë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (êµ¬ë³„)
    """
    df = pd.read_csv(csv_path, encoding="utf-8")
    df["DIST"] = df["ADDR"].apply(extract_district)
    df = df[df["DIST"].isin(DISTRICTS)].copy()
    df["DC_CN"] = df["DC_CN"].fillna("").map(clean_text)

    print("[êµ¬ë³„ ë ˆì½”ë“œ ìˆ˜]")
    print(df["DIST"].value_counts().reindex(DISTRICTS).fillna(0).astype(int).to_string())

    # êµ¬ë³„ë¡œ ëª…ì‚¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¹ˆë„ ê³„ì‚°
    district_nouns = {}
    for dist in DISTRICTS:
        sub = df[df["DIST"] == dist]
        nouns = []
        for s in sub["DC_CN"].tolist():
            nouns.extend(nouns_only(s))
        # ë¶ˆìš©ì–´, í•œ ê¸€ì ì œì™¸
        nouns = [n for n in nouns if len(n) > 1 and n not in STOPWORDS]
        district_nouns[dist] = nouns

    # ê° êµ¬ë³„ë¡œ ëª…ì‚¬ ë¹ˆë„ìˆœ ì •ë ¬
    rows = []
    for dist in DISTRICTS:
        counter = Counter(district_nouns[dist])
        for rank, (kw, cnt) in enumerate(counter.most_common(topn), 1):
            rows.append({"DIST": dist, "RANK": rank, "KEYWORD": kw, "COUNT": cnt})

    out = pd.DataFrame(rows).sort_values(["DIST", "RANK"])
    # SCRIPT_DIR/output í•˜ìœ„ì— ì €ì¥
    script_dir = Path(__file__).resolve().parent
    data_dir = script_dir / "output"
    data_dir.mkdir(exist_ok=True)
    out_path = data_dir / f"{out_prefix}_nouns_freq.csv"
    out.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"\nì €ì¥: {out_path}")

    # ì½˜ì†” ìš”ì•½
    for dist in DISTRICTS:
        sub = out[out["DIST"] == dist].head(10)
        if len(sub) == 0:
            print(f"- {dist}: (ê²°ê³¼ ì—†ìŒ)")
        else:
            print(f"- {dist}: " + ", ".join(sub["KEYWORD"].tolist()))

    return out

# ----------------------------------------------------------
# 1. ë°ì´í„° ë¡œë“œ
# ----------------------------------------------------------

print("ğŸ“‚ CSV íŒŒì¼ ë¡œë”© ì¤‘...")
df = pd.read_csv(INPUT_CSV, encoding="utf-8")

# ì£¼ì†Œê°€ ì—†ëŠ” ë°ì´í„°ëŠ” ë¶„ì„ ë¶ˆê°€ â†’ ì œê±°
df = df.dropna(subset=["ADDR"]).reset_index(drop=True)
print(f"âœ… ì´ ë°ì´í„° ìˆ˜: {len(df)}")

# ----------------------------------------------------------
# 2. ì£¼ì†Œ â†’ ìœ„ë„/ê²½ë„ ë³€í™˜ (ì§€ì˜¤ì½”ë”©)
# ----------------------------------------------------------

print("ğŸŒ ì§€ì˜¤ì½”ë”© ì„¤ì • ì¤‘...")

# OpenStreetMap ê¸°ë°˜ ì§€ì˜¤ì½”ë” (íƒ€ì„ì•„ì›ƒ 10ì´ˆë¡œ ì„¤ì •)
geolocator = Nominatim(user_agent="gwangju_architecture_gis", timeout=10)

# ìš”ì²­ ì†ë„ ì œí•œ (ì„œë²„ ë³´í˜¸ ëª©ì )
geocode = RateLimiter(
    geolocator.geocode,
    min_delay_seconds=1,
    swallow_exceptions=True,
    max_retries=3
)

def geocode_address(address):
    """
    ì£¼ì†Œ ë¬¸ìì—´ì„ ì…ë ¥ë°›ì•„ ìœ„ë„(latitude), ê²½ë„(longitude)ë¥¼ ë°˜í™˜
    """
    try:
        location = geocode(address, timeout=10)
        if location:
            return pd.Series([location.latitude, location.longitude])
        else:
            return pd.Series([None, None])
    except Exception as e:
        print(f"  âš ï¸ ì§€ì˜¤ì½”ë”© ì‹¤íŒ¨: {address}")
        return pd.Series([None, None])

print("ğŸ“ ì£¼ì†Œ â†’ ìœ„Â·ê²½ë„ ë³€í™˜ ì¤‘...")
tqdm.pandas()

df[["latitude", "longitude"]] = df["ADDR"].progress_apply(geocode_address)

print("âœ… ì§€ì˜¤ì½”ë”© ì™„ë£Œ")

# ----------------------------------------------------------
# 3. ì£¼ì†Œì—ì„œ 'êµ¬(å€)' ì •ë³´ ì¶”ì¶œ
# ----------------------------------------------------------

df["district"] = df["ADDR"].apply(extract_district)

print("ğŸ“Œ êµ¬ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ")

# ----------------------------------------------------------
# 4. êµ¬ë³„ í‚¤ì›Œë“œ ë¶„ì„ (ì„¤ëª…ë‚´ìš© ê¸°ë°˜)
# ----------------------------------------------------------

# ê¸°ì¡´ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‚¬ìš©: clean_text(), nouns_only(), ë“±

district_keywords = {}

for district in df["district"].unique():
    texts = df[df["district"] == district]["DC_CN"].dropna()
    
    words = []
    for text in texts:
        words.extend(clean_text(text))
    
    # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
    counter = Counter(words)
    
    # ë„ˆë¬´ ì¼ë°˜ì ì¸ ë‹¨ì–´ ì œê±°
    stopwords = ["ìˆë‹¤", "ì´ë‹¤", "í•œë‹¤", "ìˆëŠ”", "ëŒ€í•œ", "ìœ„í•´", "ê´€ë ¨"]
    for stopword in stopwords:
        counter.pop(stopword, None)
    
    # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ì €ì¥
    district_keywords[district] = counter.most_common(10)

print("\nğŸ“Š êµ¬ë³„ ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼")
for district, keywords in district_keywords.items():
    print(f"\n[{district}]")
    for word, count in keywords:
        print(f" - {word}: {count}")

# ----------------------------------------------------------
# 5. ì§€ë„ ì‹œê°í™” (ìœ„ì¹˜ ì •ë³´ ì¤‘ì‹¬)
# ----------------------------------------------------------

print("\nğŸ—ºï¸ ì§€ë„ ì‹œê°í™” ìƒì„± ì¤‘...")

# ----------------------------------------------------------
# 5-1. êµ¬ë³„ ê±´ì¶•ë¬¼ ê°œìˆ˜ í†µê³„
# ----------------------------------------------------------

district_counts = df["district"].value_counts().sort_values(ascending=False)

print("\nğŸ“Š êµ¬ë³„ ê±´ì¶•ë¬¼ ê°œìˆ˜ í˜„í™©")
print("=" * 40)
for district, count in district_counts.items():
    print(f"{district:10} : {count:3}ê°œ")
print("=" * 40)
print(f"ì´í•©: {district_counts.sum()}ê°œ")

# ----------------------------------------------------------
# 5-2. ìš©ë„ë³„ ê±´ì¶•ë¬¼ ê°œìˆ˜ í†µê³„
# ----------------------------------------------------------

purpose_counts = df["BULD_PURPS_NM"].value_counts().sort_values(ascending=False)

print("\nğŸ“Š ìš©ë„ë³„ ê±´ì¶•ë¬¼ ê°œìˆ˜ í˜„í™©")
print("=" * 50)
for purpose, count in purpose_counts.items():
    print(f"{purpose:20} : {count:3}ê°œ")
print("=" * 50)
print(f"ì´í•©: {purpose_counts.sum()}ê°œ")

# êµ¬ë³„ ìƒ‰ìƒ ì§€ì •
district_colors = {
    "ë™êµ¬": "blue",
    "ì„œêµ¬": "red",
    "ë‚¨êµ¬": "green",
    "ë¶êµ¬": "purple",
    "ê´‘ì‚°êµ¬": "orange",
    "ê¸°íƒ€": "gray"
}

# ê´‘ì£¼ ì¤‘ì‹¬ ì¢Œí‘œ
GWANGJU_CENTER = [35.1595, 126.8526]

m = folium.Map(
    location=GWANGJU_CENTER,
    zoom_start=12,
    tiles="OpenStreetMap"
)

for _, row in df.dropna(subset=["latitude", "longitude"]).iterrows():
    # ëª…ì‚¬ ë¹ˆë„ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
    district = row['district']
    keywords_list = district_keywords.get(district, [])
    keywords_html = ""
    if keywords_list:
        keywords_text = ", ".join([kw for kw, _ in keywords_list[:5]])
        keywords_html = f"<br><br><strong>ğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ:</strong><br>{keywords_text}"
    
    popup_text = f"""
    <div style="font-family: Arial; width: 300px;">
        <b>{row['PLACE_NM']}</b><br>
        ì£¼ì†Œ: {row['ADDR']}<br>
        êµ¬: {row['district']}<br>
        ëª©ì : {row['BULD_PURPS_NM']}<br>
        ì‹œëŒ€: {row['ERA_NM']}{keywords_html}
    </div>
    """
    
    # êµ¬ë³„ë¡œ ë‹¤ë¥¸ ìƒ‰ìƒ ì ìš©
    marker_color = district_colors.get(row['district'], "gray")
    
    folium.Marker(
        location=[row["latitude"], row["longitude"]],
        popup=folium.Popup(popup_text, max_width=350),
        icon=folium.Icon(icon="building", prefix="fa", color=marker_color)
    ).add_to(m)

# ë²”ë¡€ ì¶”ê°€ (êµ¬ë³„ + ìš©ë„ë³„)
legend_html = """
<div style="position: fixed; 
     bottom: 50px; right: 50px; width: 280px; height: auto; max-height: 600px;
     background-color: white; border:2px solid grey; z-index:9999; 
     font-size:13px; padding: 10px; border-radius: 5px; overflow-y: auto;">
     <p style="margin: 0 0 8px 0; font-weight: bold; border-bottom: 2px solid #ddd; padding-bottom: 5px;">ğŸ›ï¸ êµ¬ë³„ (ìƒ‰ìƒ)</p>
"""
for district, color in district_colors.items():
    count = district_counts.get(district, 0)
    legend_html += f'<p style="margin: 3px 0;"><i class="fa fa-map-marker" style="color:{color}"></i> {district}: {count}ê°œ</p>'
    
legend_html += """
     <p style="margin: 10px 0 8px 0; font-weight: bold; border-top: 1px solid #ddd; border-bottom: 2px solid #ddd; padding: 5px 0;">ğŸ¢ ìš©ë„ë³„</p>
"""

# ìš©ë„ë³„ ìƒìœ„ 10ê°œë§Œ ë²”ë¡€ì— í‘œì‹œ
for purpose, count in purpose_counts.head(10).items():
    legend_html += f'<p style="margin: 3px 0;">â€¢ {purpose}: {count}ê°œ</p>'

if len(purpose_counts) > 10:
    legend_html += f'<p style="margin: 5px 0; font-style: italic; color: #666;">+ ì™¸ {len(purpose_counts)-10}ê°œ ìš©ë„</p>'

legend_html += """
</div>
"""

m.get_root().html.add_child(folium.Element(legend_html))

m.save(OUTPUT_MAP)

print(f"âœ… ì§€ë„ íŒŒì¼ ìƒì„± ì™„ë£Œ â†’ {OUTPUT_MAP}")

# ----------------------------------------------------------
# 6. ê²°ê³¼ CSV ì €ì¥
# ----------------------------------------------------------

df.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")
print(f"ğŸ’¾ ì¢Œí‘œ í¬í•¨ CSV ì €ì¥ ì™„ë£Œ â†’ {OUTPUT_CSV}")

print("\nğŸ‰ ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!")
